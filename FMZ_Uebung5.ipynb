{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FMZ Übung 5: **Lineare und Nichtlineare Regression**\n",
        "\n",
        "---\n",
        "### Ziel der Übung\n",
        "- Unterschied zwischen linearer und nichtlinearer Regression verstehen\n",
        "- Modelle schätzen, interpretieren & visualisieren\n",
        "- Modelle auf synthetische & reale Daten anwenden\n",
        "- Modellgüte beurteilen (R², Residuenanalyse, Overfitting)\n",
        "- Erweiterung: ML-Regressionsmethoden (Random Forest, SVR, Neural Net)\n",
        "\n",
        "\n",
        "---\n",
        "### Benötigte Pakete\n",
        "\n",
        "```{r, eval=FALSE}\n",
        " # install.packages(c(\"randomForest\",\"e1071\",\"neuralnet\"))\n",
        " library(ggplot2)\n",
        " library(neuralnet)\n",
        " library(randomForest)\n",
        " library(e1071)\n",
        "```\n",
        "---\n"
      ],
      "metadata": {
        "id": "x49vPU-RTLDU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkSox_g-TKEh"
      },
      "outputs": [],
      "source": [
        "\n",
        " install.packages(c(\"randomForest\",\"e1071\",\"neuralnet\"))\n",
        " library(ggplot2)\n",
        " library(neuralnet)\n",
        " library(randomForest)\n",
        " library(e1071)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aufgabe 1: **Einfache lineare Regression**\n",
        "\n",
        "---\n",
        "### Datensatz simulieren\n",
        "```{r, eval=FALSE}\n",
        " set.seed(123)\n",
        " n <- 500\n",
        " x <- runif(n,0,10)\n",
        " y <- 2 + 0.8*x + rnorm(n,0,1)\n",
        " data_lin <- data.frame(x,y)\n",
        " head(data_lin)\n",
        "```\n",
        "\n",
        "---\n",
        "### Plot der Daten\n",
        "```{r, eval=FALSE}\n",
        " plot(x,y)\n",
        "```\n",
        "\n",
        "---\n",
        "### Einfache lineare Regression\n",
        "```{r, eval=FALSE}\n",
        " model_lin <- lm(y ~ x, data=data_lin)\n",
        " summary(model_lin)\n",
        "```\n",
        "---\n",
        "### Plot des linearen Modells\n",
        "```{r, eval=FALSE}\n",
        " plot(data_lin$x,data_lin$y)\n",
        " abline(model_lin,col=2,lwd=2)\n",
        "\n",
        " ggplot(data_lin, aes(x,y)) +          # mit ggplot\n",
        "   geom_point() +\n",
        "   geom_smooth(method=\"lm\", se=FALSE, color=\"blue\") +\n",
        "   labs(title=\"Einfache lineare Regression\")\n",
        "\n",
        " hist(residuals(model_lin), freq = F, main = \"Histogramm der Residuen\")\n",
        " curve(dnorm(x, mean(residuals(model_lin)), sd(residuals(model_lin))), col = 2, lwd = 2, add = T)\n",
        "\n",
        " qqnorm(residuals(model_lin))\n",
        " qqline(residuals(model_lin), col=\"red\", lwd=2)\n",
        "\n",
        " shapiro.test(residuals(model_lin))\n",
        "```\n",
        "---\n",
        "\n",
        "### Aufgaben\n",
        "\n",
        "- Interpretieren Sie die Regressionskoeffizienten\n",
        "- Was bedeutet der p-Wert?\n",
        "- Ist das Modell gut geeignet (R²)?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "9mcKjtWYUdEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " set.seed(123)\n",
        " n <- 500\n",
        " x <- runif(n,0,10)\n",
        " y <- 2 + 0.8*x + rnorm(n,0,1)\n",
        " data_lin <- data.frame(x,y)\n",
        "\n",
        " model_lin <- lm(y ~ x, data=data_lin)\n",
        " summary(model_lin)\n",
        " plot(data_lin)\n",
        " abline(model_lin,col=2,lwd=2)\n",
        "\n",
        " ggplot(data_lin, aes(x,y)) +              # mit ggplot\n",
        "   geom_point() +\n",
        "   geom_smooth(method=\"lm\", se=FALSE, color=\"blue\") +\n",
        "   labs(title=\"Einfache lineare Regression\")\n",
        "\n",
        " hist(residuals(model_lin), freq = F, main = \"Histogramm der Residuen\")\n",
        " curve(dnorm(x, mean(residuals(model_lin)), sd(residuals(model_lin))), col = 2, lwd = 2, add = T)\n",
        " qqnorm(residuals(model_lin))\n",
        " qqline(residuals(model_lin), col=\"red\", lwd=2)\n",
        "\n",
        " shapiro.test(residuals(model_lin))\n"
      ],
      "metadata": {
        "id": "fwTuhYPVVOul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aufgabe 2: **Nichtlineare Daten → Versagen der linearen Regression**\n",
        "\n",
        "---\n",
        "### Nichtlinearer Datensatz simulieren\n",
        "```{r, eval=FALSE}\n",
        " set.seed(123)\n",
        " x <- seq(0,5,length.out=n)\n",
        " y <- 3*sin(2*x) + rnorm(n,0,0.3)\n",
        " data_nonlin <- data.frame(x,y)\n",
        " head(data_nonlin)\n",
        "```\n",
        "\n",
        "---\n",
        "### Einfache lineare Regression\n",
        "```{r, eval=FALSE}\n",
        " model_lin_bad <- lm(y ~ x, data=data_nonlin)\n",
        " summary(model_lin_bad)\n",
        "```\n",
        "\n",
        "---\n",
        "### Plot\n",
        "```{r, eval=FALSE}\n",
        " ggplot(data_nonlin, aes(x,y)) +          \n",
        "    geom_point() +\n",
        "    geom_smooth(method=\"lm\", se=FALSE, color=\"blue\") +\n",
        "    labs(title=\"Lineare Regression auf nichtlinearen Daten\")\n",
        " hist(residuals(model_lin_bad), freq = F, main = \"Histogramm der Residuen\")\n",
        " curve(dnorm(x, mean(residuals(model_lin_bad)), sd(residuals(model_lin_bad))), col = 2, lwd = 2, add = T)\n",
        "\n",
        " qqnorm(residuals(model_lin_bad))\n",
        " qqline(residuals(model_lin_bad), col=\"red\", lwd=2)\n",
        "\n",
        " shapiro.test(residuals(model_lin_bad))\n",
        "```\n",
        "---\n",
        "\n",
        "### Aufgaben\n",
        "- Warum passt das Modell schlecht?\n",
        "- Welche Struktur hat der Fehler?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vIc4V08MXZP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " set.seed(123)\n",
        " x <- seq(0,5,length.out=n)\n",
        " y <- 3*sin(2*x) + rnorm(n,0,1)\n",
        " data_nonlin <- data.frame(x,y)\n",
        " head(data_nonlin)\n",
        " model_lin_bad <- lm(y ~ x, data=data_nonlin)\n",
        " summary(model_lin_bad)\n",
        "\n",
        " ggplot(data_nonlin, aes(x,y)) +\n",
        "   geom_point() +\n",
        "   geom_smooth(method=\"lm\", se=FALSE, color=\"blue\") +\n",
        "   labs(title=\"Lineare Regression auf nichtlinearen Daten\")\n",
        "\n",
        " hist(residuals(model_lin_bad), freq = F, main = \"Histogramm der Residuen\")\n",
        " curve(dnorm(x, mean(residuals(model_lin_bad)), sd(residuals(model_lin_bad))), col = 2, lwd = 2, add = T)\n",
        "\n",
        " qqnorm(residuals(model_lin_bad))\n",
        " qqline(residuals(model_lin_bad), col=\"red\", lwd=2)\n",
        "\n",
        " shapiro.test(residuals(model_lin_bad))\n"
      ],
      "metadata": {
        "id": "ENRB4AcLne71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aufgabe 3: **Nichtlineare Regression - Polynommodell (`poly`)**\n",
        "\n",
        "---\n",
        "### Polynomregression\n",
        "```{r, eval=FALSE}\n",
        " grad <- 3\n",
        " model_poly <- lm(y ~ poly(x,grad), data=data_nonlin)\n",
        " summary(model_poly)\n",
        "```\n",
        "\n",
        "---\n",
        "### Plot\n",
        "```{r, eval=FALSE}\n",
        " ggplot(data_nonlin,aes(x,y)) +\n",
        "   geom_point(alpha=.5) +\n",
        "   geom_smooth(method=\"lm\", formula=y~poly(x,grad), se=FALSE, color=\"blue\") +\n",
        "   labs(title=paste(\"Polynomregression (Grad \",grad,\") - R²=\",round(summary(model_poly)$r.squared,2),sep=\"\"))\n",
        "```\n",
        "---\n",
        "### Aufgaben\n",
        "- Probieren Sie unterschiedliche Grade 2, 4, 6, 8, 10 → Overfitting beobachten\n",
        "---"
      ],
      "metadata": {
        "id": "VlXoQ4cyt3L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "par(mfrow=c(2,2))\n",
        "for(grad in c(2,4,6,8)){\n",
        " model_poly <- lm(y ~ poly(x,grad), data=data_nonlin)\n",
        " summary(model_poly)\n",
        "\n",
        " print(ggplot(data_nonlin,aes(x,y)) +\n",
        "   geom_point(alpha=.5) +\n",
        "   geom_smooth(method=\"lm\", formula=y~poly(x,grad), se=FALSE, color=\"blue\") +\n",
        "   labs(title=paste(\"Polynomregression (Grad\",grad,\") - R² =\",round(summary(model_poly)$r.squared,2))))}\n",
        ""
      ],
      "metadata": {
        "id": "E6SKNhMBuj1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aufgabe 4: **Nichtlineare Regression (`nls`)**\n",
        "\n",
        "\n",
        "---\n",
        "### Nichtlineare Regression\n",
        "```{r, eval=FALSE}\n",
        " mod_NLS <- nls(y ~ a * sin(b*x), data=data_nonlin, start=list(a=4,b=1.5))\n",
        " summary(mod_NLS)\n",
        "```\n",
        "\n",
        "---\n",
        "### Plot\n",
        "```{r, eval=FALSE}\n",
        " plot(data_nonlin$x,data_nonlin$y)\n",
        " lines(x, predict(mod_NLS), col=2,lwd=2)\n",
        "```\n",
        "\n",
        "---\n",
        "### Aufgaben\n",
        "- Ändern Sie die Anfangswerte der Parameter im Befehl `NLS`. Was fällt Ihnen auf?\n",
        "---\n"
      ],
      "metadata": {
        "id": "POTQXW6IwRSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " mod_NLS <- nls(y ~ a * sin(b*x), data=data_nonlin, start=list(a=4,b=1.5))\n",
        " summary(mod_NLS)\n",
        " plot(data_nonlin$x,data_nonlin$y)\n",
        " lines(x, predict(mod_NLS), col=2,lwd=2)\n"
      ],
      "metadata": {
        "id": "vy6SAt1dx-WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aufgabe 5: **Machine-Learning-Regressoren (Kurz-Demo)**\n",
        "\n",
        "\n",
        "---\n",
        "### R²-Funktion\n",
        "```{r, eval=FALSE}\n",
        " R2 <- function(y_pred) {\n",
        "   1 - sum((y_pred - y)^2) / sum((y - mean(y))^2)}\n",
        "```\n",
        "\n",
        "---\n",
        "### Random Forest Regressor\n",
        "```{r, eval=FALSE}\n",
        " set.seed(123)\n",
        " rf <- randomForest(y~x,data_nonlin)\n",
        " plot(x,y)\n",
        " lines(x,predict(rf),col=\"blue\",lwd=2)\n",
        " R2(predict(rf))\n",
        "```\n",
        "\n",
        "---\n",
        "### Support Vector Regression\n",
        "```{r, eval=FALSE}\n",
        "  <- svm(y~x,data_nonlin)\n",
        " lines(x,predict(svm),col=\"red\",lwd=2)\n",
        " R2(predict(svm))\n",
        "```\n",
        "\n",
        "---\n",
        "### Neuronales Netz\n",
        "```{r, eval=FALSE}\n",
        " nn <- neuralnet(y~x, data_nonlin, hidden=2)\n",
        " lines(x,predict(nn, newdata=data_nonlin),col=\"green\",lwd=2)\n",
        " R2(predict(nn, newdata=data_nonlin))\n",
        "```\n",
        "---\n",
        "### Aufgaben\n",
        "- Welcher Algorithmus passt am besten?\n",
        "- Ändern Sie die Hyperparameter der ML-Regressoren (Anzahl der Bäume `ntree`, Kernelart `Kernel`, Anzahl der Schichten und Neuronen `hidden`, usw.). Was fällt Ihnen auf?\n",
        "---\n"
      ],
      "metadata": {
        "id": "eduVwjC4z1bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "R2 <- function(y_pred) {\n",
        "  1 - sum((y_pred - y)^2) / sum((y - mean(y))^2)}\n",
        "\n",
        "set.seed(123)\n",
        "rf <- randomForest(y~x,data_nonlin)\n",
        "plot(x,y)\n",
        "lines(x,predict(rf),col=\"blue\",lwd=2)\n",
        "R2(predict(rf))\n",
        "\n",
        "svm <- svm(y~x,data_nonlin)\n",
        "lines(x,predict(svm),col=\"red\",lwd=5)\n",
        "R2(predict(svm))\n",
        "\n",
        "nn <- neuralnet(y~x, data_nonlin, hidden=2)\n",
        "lines(x,predict(nn, newdata=data_nonlin),col=\"green\",lwd=5)\n",
        "R2(predict(nn, newdata=data_nonlin))\n"
      ],
      "metadata": {
        "id": "p5g1JBHhEK27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zusätzliche Aufgabe\n",
        "\n",
        "---\n",
        "### Laden des Fußgängerdynamik-Datensatzes\n",
        " ```{r, eval=FALSE}\n",
        " set.seed(123)\n",
        " ped <- read.table(\"https://raw.githubusercontent.com/antoinetordeux/Datasets/refs/heads/main/ped_data.txt\", header=TRUE)\n",
        " head(ped)\n",
        " attach(ped)\n",
        " ```\n",
        "\n",
        "### Plotfunktion\n",
        " ```{r, eval=FALSE}\n",
        " plot_res <- function(algo,title){\n",
        "   plot(Spacing,Speed,xlab='Spacing',ylab='Speed',main=title)\n",
        "   y_pred <- predict(algo, ped)\n",
        "   lines(sort(Spacing), y_pred[order(Spacing)], col=2,lwd=2)\n",
        "   legend(\"bottomright\", paste(\"R² =\",round(1 - var(y_pred-Speed)/var(Speed),2)),bty='n')\n",
        "   print(summary(algo))\n",
        " }\n",
        "```\n",
        "\n",
        "\n",
        "---\n",
        "### Einfache lineare Regression\n",
        " ```{r, eval=FALSE}\n",
        " m_ped <- lm(Speed ~ Spacing, data=ped)\n",
        " par(mfrow=c(2,2))\n",
        " plot_res(m_ped,\"Einfache lineare Regression\")\n",
        "```\n",
        "\n",
        "---\n",
        "### Nichtlineare Regression\n",
        "```{r, eval=FALSE}\n",
        " nl-model <- function(x,v0,l0,T,eps){\n",
        "    eps/T*log(1+exp(-log(1+exp(-(x-l0-v0*T)/eps))+v0*T/eps))}\n",
        "    \n",
        " m_ped_NLS <- nls(Speed~nl_model(Spacing,v0,l0,T,eps),\n",
        "          start=list(v0=1.2,l0=0.3,T=.8,eps=.01))\n",
        " plot_res(m_ped_NLS,\"Nichtlineares Modell\")\n",
        "```\n",
        "\n",
        "---\n",
        "### Multiple lineare Regression\n",
        " ```{r, eval=FALSE}\n",
        " m_ped_multi <- lm(Speed ~ Spacing + Spacing_pred + Speed_pred + Acceleration, data=ped)\n",
        " plot_res(m_ped_multi,\"Multiple lineare Regression\")\n",
        "```\n",
        "\n",
        "---\n",
        "### Random Forest Regressor\n",
        " ```{r, eval=FALSE}\n",
        " m_ped_rf  <- randomForest(Speed ~ Spacing + Spacing_pred + Speed_pred + Acceleration, data=ped)\n",
        " plot_res(m_ped_rf,\"Random Forest\")\n",
        "```\n",
        "\n",
        "---\n",
        "### Support Vector Regression\n",
        " ```{r, eval=FALSE}\n",
        " m_ped_svm <- svm(Speed ~ Spacing + Spacing_pred + Speed_pred + Acceleration, data=ped)\n",
        " plot_res(m_ped_svm,\"SVM\")\n",
        "```\n",
        "\n",
        "---\n",
        "### Neuronales Netz\n",
        " ```{r, eval=FALSE}\n",
        " m_nn <- neuralnet(Speed ~ Spacing + Spacing_pred + Speed_pred + Acceleration, data=ped, hidden=2)\n",
        " plot_res(m_nn,\"Neural Net\")\n",
        "```\n",
        "\n",
        "---\n",
        "### Aufgabe\n",
        "- Welcher Algorithmus passt am besten?\n",
        "- Implementieren Sie einfache Regressionen zwischen `Speed` und `Spacing` mit dem Random-Forest-Algorithmus, der SVM und dem neuronalen Netzwerk. Was fällt Ihnen auf?\n"
      ],
      "metadata": {
        "id": "76E3Pf2YMLLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " ped <- read.table(\"https://raw.githubusercontent.com/antoinetordeux/Datasets/refs/heads/main/ped_data.txt\", header=TRUE)\n",
        " head(ped)\n",
        " attach(ped)\n",
        " plot_res <- function(algo,title){\n",
        "   plot(Spacing,Speed,xlab='Spacing',ylab='Speed',main=title)\n",
        "   y_pred <- predict(algo, ped)\n",
        "   lines(sort(Spacing), y_pred[order(Spacing)], col=2,lwd=2)\n",
        "   legend(\"bottomright\", paste(\"R² =\",round(1 - var(y_pred-Speed)/var(Speed),2)),bty='n')\n",
        "   print(summary(algo))\n",
        " }\n",
        "\n",
        "set.seed(123)\n",
        "m_ped <- lm(Speed ~ Spacing, data=ped)\n",
        "par(mfrow=c(2,2))\n",
        "plot_res(m_ped,\"Einfache lineare Regression\")\n",
        "\n",
        " m_ped_multi <- lm(Speed ~ Spacing + Spacing_pred + Speed_pred + Acceleration, data=ped)\n",
        " plot_res(m_ped_multi,\"Multiple lineare Regression\")\n",
        "\n",
        "  nl_model <- function(x,v0,l0,T,eps){\n",
        "    eps/T*log(1+exp(-log(1+exp(-(x-l0-v0*T)/eps))+v0*T/eps))\n",
        "}\n",
        " m_ped_NLS <- nls(Speed~nl_model(Spacing,v0,l0,T,eps),\n",
        "          start=list(v0=1.2,l0=0.3,T=.8,eps=.01))\n",
        " plot_res(m_ped_NLS,\"Nichtlineares Modell\")\n",
        "\n",
        "m_ped_rf  <- randomForest(Speed ~ Spacing + Spacing_pred + Speed_pred + Acceleration, data=ped)\n",
        "plot_res(m_ped_rf,\"Random Forest\")\n",
        "\n",
        "m_ped_svm <- svm(Speed ~ Spacing + Spacing_pred + Speed_pred + Acceleration, data=ped)\n",
        "plot_res(m_ped_svm,\"SVM\")\n",
        "\n",
        "m_nn <- neuralnet(Speed ~ Spacing + Spacing_pred + Speed_pred + Acceleration, data=ped, hidden=2)\n",
        "plot_res(m_nn,\"Neural Net\")\n"
      ],
      "metadata": {
        "id": "SCPAEECXONg_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}